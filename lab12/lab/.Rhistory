CarseatsHB = levels(CarseatsH$High)[CarseatsH$High]
CarseatsHB$High = as.numeric(CarseatsH$High)
CarseatsHB2 <- CarseatsH
CarseatsHB2$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
CarseatsHB = levels(CarseatsH$High)[CarseatsH$High]
CarseatsHB$High = as.numeric(CarseatsH$High)
summary(CarseatsHB)
CarseatsHB2 <- CarseatsH
CarseatsHB2$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
summary(CarseatsHB)
CarseatsHB = levels(CarseatsH$High)[CarseatsH$High]
CarseatsHB$High = as.numeric(CarseatsH$High)
summary(CarseatsHB)
CarseatsHB2 <- CarseatsH
CarseatsHB2$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
summary(CarseatsHB)
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB = levels(CarseatsH$High)[CarseatsH$High]
CarseatsHB$High = as.numeric(CarseatsH$High)
summary(CarseatsHB)
CarseatsHB2 <- CarseatsH
CarseatsHB2$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
summary(CarseatsHB)
CarseatsHB = levels(CarseatsH$High)[CarseatsH$High]
CarseatsHB$High = as.numeric(CarseatsH$High)
summary(CarseatsHB)
CarseatsHB2 <- CarseatsH
CarseatsHB2$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
summary(CarseatsHB)
CarseatsHB = levels(CarseatsH$High)[CarseatsH$High]
CarseatsHB$High = as.numeric(CarseatsH$High)
summary(CarseatsHB)
CarseatsH2 <- CarseatsH
CarseatsH2$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
summary(CarseatsHB)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsH2[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.class <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.class <- round(plogis(sales.high.boost.class ))
sales.high.boost
y_true <- CarseatsH2$High[test]
y_pred <- sales.high.boost.class
table(y_pred, y_true)
mean(y_pred != y_true)
CarseatsH$High = levels(CarseatsH$High)[CarseatsH$High]
CarseatsH$High = as.numeric(CarseatsH$High)
set.seed(1)
high.boost <- gbm(High ~ . - Sales, data = CarseatsH[train,], distribution = "bernoulli",
interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
high.pred.boost <- predict(high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Otrzymane predykcje są liczbami rzeczywistymi z bardzo szerokiego przedziału,
# musimy więc je zdyskretyzować sprowadzając do dwóch możliwych wartości 0/1.
high.pred.boost.discreet = ifelse(high.pred.boost <= 0.5, 0, 1)
100*mean(high.pred.boost.discreet != CarseatsH$High[test])
CarseatsH$High = levels(CarseatsH$High)[CarseatsH$High]
CarseatsH$High = as.numeric(CarseatsH$High)
set.seed(1)
high.boost <- gbm(High ~ . - Sales, data = CarseatsH[train,], distribution = "bernoulli",
interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
high.pred.boost <- predict(high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Otrzymane predykcje są liczbami rzeczywistymi z bardzo szerokiego przedziału,
# musimy więc je zdyskretyzować sprowadzając do dwóch możliwych wartości 0/1.
high.pred.boost.discreet = ifelse(high.pred.boost <= 0.5, 0, 1)
100*mean(high.pred.boost.discreet != CarseatsH$High[test])
CarseatsH$High = levels(CarseatsH$High)[CarseatsH$High]
CarseatsH$High = as.numeric(CarseatsH$High)
set.seed(1)
high.boost <- gbm(High ~ . - Sales, data = CarseatsH[train,], distribution = "bernoulli",
interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
high.pred.boost <- predict(high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Otrzymane predykcje są liczbami rzeczywistymi z bardzo szerokiego przedziału,
# musimy więc je zdyskretyzować sprowadzając do dwóch możliwych wartości 0/1.
high.pred.boost.discreet = ifelse(high.pred.boost <= 0.5, 0, 1)
100*mean(high.pred.boost.discreet != CarseatsH$High[test])
CarseatsH$High = levels(CarseatsH$High)[CarseatsH$High]
CarseatsH$High = as.numeric(CarseatsH$High)
set.seed(1)
high.boost <- gbm(High ~ . - Sales, data = CarseatsH[train,], distribution = "bernoulli",
interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
high.pred.boost <- predict(high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Otrzymane predykcje są liczbami rzeczywistymi z bardzo szerokiego przedziału,
# musimy więc je zdyskretyzować sprowadzając do dwóch możliwych wartości 0/1.
high.pred.boost.discreet = ifelse(high.pred.boost <= 0.5, 0, 1)
100*mean(high.pred.boost.discreet != CarseatsH$High[test])
CarseatsH$High = levels(CarseatsH$High)[CarseatsH$High]
CarseatsH$High = as.numeric(CarseatsH$High)
set.seed(1)
high.boost <- gbm(High ~ . - Sales, data = CarseatsH[train,], distribution = "bernoulli",
interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
high.pred.boost <- predict(high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsH$High = levels(CarseatsH$High)[CarseatsH$High]
CarseatsH$High = as.numeric(CarseatsH$High)
set.seed(1)
high.boost <- gbm(High ~ . - Sales, data = CarseatsH[train,], distribution = "bernoulli",
interaction.depth = 4, n.trees = 5000, shrinkage = 0.01)
high.pred.boost <- predict(high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Otrzymane predykcje są liczbami rzeczywistymi z bardzo szerokiego przedziału,
# musimy więc je zdyskretyzować sprowadzając do dwóch możliwych wartości 0/1.
high.pred.boost.discreet = ifelse(high.pred.boost <= 0.5, 0, 1)
100*mean(high.pred.boost.discreet != CarseatsH$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- round(plogis(sales.high.boost.class ))
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- round(plogis(sales.high.boost.pred))
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- ifelse(high.pred.boost <= 0.5, 0, 1)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- ifelse(high.pred.boost <= 0.5, 0, 1)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- round(plogis(sales.high.boost.pred))
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- round(sales.high.boost.pred)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- ifelse(sales.high.boost.pred <= 0.5, 0, 1)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
# Zadanie 2, lab6, Paweł Mendroch
library(ISLR)
library(randomForest)
library(tree)
library(gbm)
attach(Carseats)
set.seed(1)
High <- factor(ifelse(Carseats$Sales <= 8, "No", "Yes"))
CarseatsH <- data.frame(Carseats, High)
n <- nrow(CarseatsH)
train <- sample(1:n, n / 2)
test <- -train
# Bagging
sales.high.bag <- randomForest(High ~ . - Sales, data = CarseatsH, mtry = 10, importance = TRUE, subset = train)
sales.high.bag.pred <- predict(sales.high.bag, newdata = CarseatsH[test,], type = "class")
importance(sales.high.bag)
table(sales.high.bag.pred, CarseatsH$High[test])
mean(sales.high.bag.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18.5%
# Las losowy
sales.high.rf <- randomForest(High ~ . - Sales, data = CarseatsH, importance = TRUE, subset = train)
sales.high.rf.pred <- predict(sales.high.rf, newdata = CarseatsH[test,], type = "class")
importance(sales.high.rf)
table(sales.high.rf.pred, CarseatsH$High[test])
mean(sales.high.rf.pred != CarseatsH$High[test])
# Wartość błędu wynosi 18%
# Boosting
CarseatsHB <- CarseatsH
CarseatsHB$High <- ifelse(CarseatsH$High == "Yes", 1, 0)
sales.high.boost <- gbm(High ~ . - Sales, data = CarseatsHB[train,], distribution = "bernoulli",
n.trees = 5000, interaction.depth = 4)
sales.high.boost.pred <- predict(sales.high.boost, newdata = CarseatsH[test,], n.trees = 5000)
sales.high.boost.pred <- ifelse(sales.high.boost.pred <= 0.5, 0, 1)
importance(sales.high.rf)
table(sales.high.boost.pred, CarseatsHB$High[test])
mean(sales.high.boost.pred != CarseatsHB$High[test])
