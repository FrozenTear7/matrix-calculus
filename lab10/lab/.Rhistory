setwd("C:/Projects/Math/matrix-calculus/lab10/lab")
library(ISLR)
library(boot)
comp.mse.cv <- function(degree, k) {
fit.glm <- glm(mpg ~ poly(horsepower, degree), data = Auto)
cv.glm(Auto, fit.glm, K = k)$delta[1]
}
mse10 <- replicate(10, sapply(1:10, comp.mse.cv, k = 10))
mse10
plot(x = NULL, pch = 20, type = "l", ylab = "Walidacyjny MSE",
xlim = c(1, 10), ylim = c(18, 25))
for (i in 1:10) {
points(mse10[, i], pch = 20, type = "l", col = i)
}
plot(rowMeans(mse10), ylab="Walidacyjny MSE", xlab="Stopien", type="b", pch=20, col="blue")
plot(rowMeans(mse10), ylab = "Walidacyjny MSE", xlab="Stopien", type = "b", pch = 20)
plot(rowMeans(mse10), pch = 20, type = "l", ylab = "Walidacyjny MSE", xlab="Stopien")
plot(rowMeans(mse10), pch = 20, type = "l", ylab = "Walidacyjny MSE", xlab="Stopień")
library(ISLR)
library(boot)
comp.mse.cv <- function(degree, k) {
fit.glm <- glm(mpg ~ poly(horsepower, degree), data = Auto)
cv.glm(Auto, fit.glm, K = k)$delta[1]
}
mse10 <- replicate(10, sapply(1:10, comp.mse.cv, k = 10))
mse10
plot(rowMeans(mse10), pch = 20, type = "l", ylab = "Walidacyjny MSE", xlab="Stopien wielomianu")
# Zadanie 2, laboratorium wt. 11:15, 19 maja
# Autor: Paweł Mendroch
library(ISLR)
library(boot)
library(leaps)
fit.bs <- regsubsets(Salary ~ ., data = Hitters)
summary(fit.bs)
install.packages("leaps")
# Zadanie 2, laboratorium wt. 11:15, 19 maja
# Autor: Paweł Mendroch
library(ISLR)
library(boot)
library(leaps)
fit.bs <- regsubsets(Salary ~ ., data = Hitters)
summary(fit.bs)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
fit.bs.summary <- summary(fit.bs)
fit.bs.summary
# Zadanie 2, laboratorium wt. 11:15, 19 maja
# Autor: Paweł Mendroch
library(ISLR)
library(boot)
library(leaps)
fit.bs <- regsubsets(Salary ~ ., data = Hitters)
summary(fit.bs)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
fit.bs.summary <- summary(fit.bs)
fit.bs.summary
fit.bs.summary$cp
bic.min <- which.min(fit.bs.summary$bic)
bic.min
fit.bs.summary$bic[bic.min]
plot(fit.bs.summary$bic, xlab = "Liczba zmiennych", ylab = "BIC", col = "green",
type = "b", pch = 20)
points(bic.min, fit.bs.summary$bic[bic.min], col = "red", pch = 9)
plot(fit.bs, scale = "bic")
coef(fit.bs, id = 6)
plot(fit.bs, scale = "bic")
plot(fit.bs.summary$bic, xlab = "Liczba zmiennych", ylab = "BIC", col = "green",
type = "b", pch = 20)
points(bic.min, fit.bs.summary$bic[bic.min], col = "red", pch = 9)
plot(fit.bs, scale = "bic")
fit.forward <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
fit.forward.summary <- summary(fit.forward)
fit.forward.summary
fit.backward <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
fit.backward.summary <- summary(fit.backward)
fit.backward.summary
n <- nrow(Hitters)
train <- sample(c(TRUE, FALSE), n, replace = TRUE)
test <- !train
fit.bs.v <- regsubsets(Salary ~ ., data = Hitters[train,], nvmax = 19)
predict.regsubsets <- function(object, newdata, id, ...) {
model.formula <- as.formula(object$call[[2]])
mat <- model.matrix(model.formula, newdata)
coefs <- coef(object, id = id)
mat[, names(coefs)] %*% coefs
}
pred.error <- function(i, model, subset) {
pred <- predict(model, Hitters[subset,], id = i)
mean((Hitters$Salary[subset] - pred)^2)
}
val.errors <- sapply(1:19, pred.error, model = fit.bs.v, subset = test)
val.errors
Hitters = na.omit(Hitters)
pred.error <- function(i, model, subset) {
pred <- predict(model, Hitters[subset,], id = i)
mean((Hitters$Salary[subset] - pred)^2)
}
val.errors <- sapply(1:19, pred.error, model = fit.bs.v, subset = test)
val.errors
fit.bs <- regsubsets(Salary ~ ., data = Hitters)
summary(fit.bs)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
fit.bs.summary <- summary(fit.bs)
fit.bs.summary
fit.bs.summary$cp
bic.min <- which.min(fit.bs.summary$bic)
bic.min
fit.bs.summary$bic[bic.min]
plot(fit.bs.summary$bic, xlab = "Liczba zmiennych", ylab = "BIC", col = "green",
type = "b", pch = 20)
points(bic.min, fit.bs.summary$bic[bic.min], col = "red", pch = 9)
plot(fit.bs, scale = "bic")
coef(fit.bs, id = 6)
fit.forward <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
fit.forward.summary <- summary(fit.forward)
fit.forward.summary
fit.backward <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
fit.backward.summary <- summary(fit.backward)
fit.backward.summary
n <- nrow(Hitters)
train <- sample(c(TRUE, FALSE), n, replace = TRUE)
test <- !train
fit.bs.v <- regsubsets(Salary ~ ., data = Hitters[train,], nvmax = 19)
predict.regsubsets <- function(object, newdata, id, ...) {
model.formula <- as.formula(object$call[[2]])
mat <- model.matrix(model.formula, newdata)
coefs <- coef(object, id = id)
mat[, names(coefs)] %*% coefs
}
pred.error <- function(i, model, subset) {
pred <- predict(model, Hitters[subset,], id = i)
mean((Hitters$Salary[subset] - pred)^2)
}
val.errors <- sapply(1:19, pred.error, model = fit.bs.v, subset = test)
val.errors
# Zadanie 2, laboratorium wt. 11:15, 19 maja
# Autor: Paweł Mendroch
library(ISLR)
library(boot)
library(leaps)
Hitters = na.omit(Hitters)
fit.bs <- regsubsets(Salary ~ ., data = Hitters)
summary(fit.bs)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
fit.bs.summary <- summary(fit.bs)
fit.bs.summary
library(ISLR)
library(boot)
library(leaps)
Hitters = na.omit(Hitters)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
adjr2.max = which.max(fit.bs.summary$adjr2)
coef(fit.bs, id = adjr2.max)
library(ISLR)
library(boot)
library(leaps)
Hitters = na.omit(Hitters)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
adjr2.max = which.max(fit.bs.summary$adjr2)
coef(fit.bs, id = adjr2.max)
fit.bs.summary$adjr2
fit.bs.summary$adjr2[11]
# Zadanie 2, laboratorium wt. 11:15, 19 maja
# Autor: Paweł Mendroch
library(ISLR)
library(boot)
library(leaps)
Hitters = na.omit(Hitters)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
adjr2.max = which.max(fit.bs.summary$adjr2)
coef(fit.bs, id = adjr2.max)
fit.bs.summary$adjr2[adjr2.max]
# Zadanie 2, laboratorium wt. 11:15, 19 maja
# Autor: Paweł Mendroch
library(ISLR)
library(boot)
library(leaps)
Hitters = na.omit(Hitters)
fit.bs <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
fit.bs.summary <- summary(fit.bs)
adjr2.max = which.max(fit.bs.summary$adjr2)
coef(fit.bs, id = adjr2.max)
fit.bs.summary$adjr2[adjr2.max]
# Najlepsze R^2 wychodzi równe 0.522 dla 11 predyktoro
# Zadanie 1, laboratorium wt. 11:15, 19 maja
# Autor: PaweÅ Mendroch
library(ISLR)
library(boot)
comp.mse.cv <- function(degree, k) {
fit.glm <- glm(mpg ~ poly(horsepower, degree), data = Auto)
cv.glm(Auto, fit.glm, K = k)$delta[1]
}
mse10 <- replicate(10, sapply(1:10, comp.mse.cv, k = 10))
mse10
mseMeans10 = rowMeans(mse10)
mseMeans10
plot(rowMeans(mse10), pch = 20, type = "l", ylab = "Blad predykcji", xlab="Stopien wielomianu")
# 1. Najmniejszy MSE w 10-krotnej walidacji krzyÅ¼owej daje stopieÅ 5, czasami lepszy wynik daje stopieÅ 2, lecz
# wciÄÅ¼ wygrywa stopieÅ 5.
# 2. Dla zakresu do 10, na wykresie moÅ¼na zauwaÅ¼yÄ, Å¼e najmniejszy Åredni bÅÄd predykcji
# daje wielomian 7 stopnia
# Zadanie 1, laboratorium wt. 11:15, 19 maja
# Autor: PaweÅ Mendroch
library(ISLR)
library(boot)
comp.mse.cv <- function(degree, k) {
fit.glm <- glm(mpg ~ poly(horsepower, degree), data = Auto)
cv.glm(Auto, fit.glm, K = k)$delta[1]
}
mse10 <- replicate(10, sapply(1:10, comp.mse.cv, k = 10))
mse10
mseMeans10 = rowMeans(mse10)
mseMeans10
plot(rowMeans(mse10), pch = 20, type = "l", ylab = "Blad predykcji", xlab="Stopien wielomianu")
# 1. Najmniejszy MSE w 10-krotnej walidacji krzyÅ¼owej daje stopieÅ 5, czasami lepszy wynik daje stopieÅ 2, lecz
# wciÄÅ¼ wygrywa stopieÅ 5.
# 2. Dla zakresu do 10, na wykresie moÅ¼na zauwaÅ¼yÄ, Å¼e najmniejszy Åredni bÅÄd predykcji
# daje wielomian 7 stopnia
